{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "84067c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torchaudio.datasets import GTZAN\n",
    "import sys\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "sys.path.append(\"../\")\n",
    "from model.modules import CNN1D, MusicTaggingTransformer\n",
    "from model.emb_model import EmbModel\n",
    "from model.lightning_model import ZSLRunner\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim.models.keyedvectors import KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef62f33",
   "metadata": {},
   "source": [
    "# DEMO Contents\n",
    "\n",
    "- Download GTZAN\n",
    "- Load Word Model: GLOVE\n",
    "- Load Audio Model: 1D CNN\n",
    "- Projection to Joint Embedding Space\n",
    "- Seen & Unseen Query Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fc1cac",
   "metadata": {},
   "source": [
    "## Download GTZAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "854ac9c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = GTZAN(root=\".\", download=True)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5310ac31",
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform,samplerate,label= dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d64360",
   "metadata": {},
   "source": [
    "## Load Word Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fb62905",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_path = \"{your own glove model}\"\n",
    "glove_name = \"glove.42B.300d.txt\"\n",
    "# 3min?...\n",
    "glove_model = KeyedVectors.load_word2vec_format(os.path.join(glove_path, glove_name), binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00d5492",
   "metadata": {},
   "source": [
    "## Load Audio Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "383cca5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_type = \"zeroshot\"\n",
    "emb_type = \"glove\"\n",
    "backbone = \"CNN1D\"\n",
    "# backbone = \"Transformer\"\n",
    "supervisions = \"tag\"\n",
    "DEVICE = \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6605d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_path = \"../dataset/pretrained\"\n",
    "save_path = os.path.join(pretrained_path, f\"{task_type}/{emb_type}/{backbone}/{supervisions}\")\n",
    "args = OmegaConf.load(os.path.join(save_path, \"hparams.yaml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "312a332b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if backbone == \"CNN1D\":\n",
    "    backbone = CNN1D()\n",
    "    model = EmbModel(\n",
    "            audio_model = backbone,\n",
    "            projection_ndim = 100\n",
    "    )\n",
    "elif backbone == \"Transformer\":\n",
    "    backbone = MusicTaggingTransformer(conv_ndim=128, attention_ndim=64)\n",
    "    model = EmbModel(\n",
    "            audio_model = backbone,\n",
    "            projection_ndim = 64\n",
    "    )\n",
    "    \n",
    "runner = ZSLRunner(\n",
    "model = model,\n",
    "margin = args.margin, \n",
    "lr = args.lr, \n",
    "supervisions = args.supervisions,\n",
    "opt_type = args.opt_type\n",
    ")\n",
    "state_dict = torch.load(os.path.join(save_path, \"best.ckpt\"))\n",
    "runner.load_state_dict(state_dict.get(\"state_dict\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e90d5f",
   "metadata": {},
   "source": [
    "## Extract Music Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f925a2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "runner.to(DEVICE).eval()\n",
    "zeroshot_model = runner.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14f85711",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_length = args.duration * 22050\n",
    "num_chunks = 16\n",
    "item_dict = {}\n",
    "for idx, item in enumerate(dataset):\n",
    "    audio,_,label= item\n",
    "    audio = audio.squeeze(0).numpy()\n",
    "    hop = (len(audio) - input_length) // num_chunks\n",
    "    audio = np.array([audio[i * hop : i * hop + input_length] for i in range(num_chunks)]).astype('float32')\n",
    "    audio = torch.from_numpy(audio).to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        audio_emb = zeroshot_model.audio_model(audio)\n",
    "    item_dict[idx] = {\n",
    "        \"audio_emb\": audio_emb.mean(0,False).detach().cpu().numpy(),\n",
    "        \"label\": label\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be28f428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(item_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceebdcc5",
   "metadata": {},
   "source": [
    "## Query by Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c200a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_embs = np.stack([item_dict[idx]['audio_emb'] for idx in item_dict.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e214c793",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_by_tag(query, word_model, zeroshot_model, audio_embs):\n",
    "    query_emb = word_model[query]\n",
    "    with torch.no_grad():\n",
    "        joint_emb = zeroshot_model.text_projection(torch.from_numpy(query_emb).to(DEVICE))\n",
    "    joint_emb = joint_emb.unsqueeze(0).detach().cpu().numpy()\n",
    "    sim_matrix = cosine_similarity(joint_emb, audio_embs)\n",
    "    df_sim = pd.DataFrame(sim_matrix, index=[query]).T\n",
    "    top5_idx = df_sim[query].sort_values(ascending=False).head()\n",
    "    print(\"top5 music tracks: \" ,[item_dict[i]['label'] + str(i) for i in top5_idx.index])\n",
    "    return top5_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dbcd0adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top5 music tracks:  ['blues49', 'rock907', 'country261', 'rock910', 'country271']\n"
     ]
    }
   ],
   "source": [
    "query = \"guitar\"\n",
    "top5_music = query_by_tag(query, glove_model, zeroshot_model, audio_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "860e7e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top5 music tracks:  ['rock958', 'pop740', 'country244', 'rock959', 'disco341']\n"
     ]
    }
   ],
   "source": [
    "query = \"happy\"\n",
    "top5_music = query_by_tag(query, glove_model, zeroshot_model, audio_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d056d15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "958    0.644991\n",
       "740    0.635107\n",
       "244    0.628895\n",
       "959    0.623938\n",
       "341    0.618849\n",
       "Name: happy, dtype: float32"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top5_music"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
